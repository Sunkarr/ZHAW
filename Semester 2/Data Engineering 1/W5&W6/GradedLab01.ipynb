{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering 1: Graded Lab 01\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grading\n",
    "For this graded lab you can get a total of 10 points. These 10 points count 10% of your final grade for the course.\n",
    "\n",
    "#### Start\n",
    "Start of the Graded Lab 01 is **Thursday, March 21st at 23:55**.\n",
    "\n",
    "#### Deadline\n",
    "Deadline for the submission of the Graded Lab 01 is **Thursday, April 11th at 23:59**.\n",
    "\n",
    "#### Note\n",
    "Check each result carefully. Use data filter, cleaning, and transformation methods wherever needed. The data can sometimes be really messy and have hidden issues.\n",
    "\n",
    "#### Submission\n",
    "You are allowed to submit the solution in groups of **two or three** students.\n",
    "Submit your GradedLab01.ipynb file renamed to FirstnameStudent01LastnameStudent01_FirstnameStudent02LastnameStudent02_FirstnameStudent03LastnameStudent03.ipynb in moodle.   \n",
    "Please submit a runnable python jupyter notebook file.\n",
    "All other submissions will be rejected and graded with 0 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 01: Structured Data [4 points].    \n",
    "The imdb.csv file contains a dataset extracted from IMDB with several attributes. For example, the title, plot, and the language of the movies. Read the imdb.csv file in a pandas dataframe and try to answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(a)  What is the min, max, and the average value of the attribute 'rating' for all movies? [0.5 points].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.516919Z",
     "start_time": "2024-03-29T14:33:41.117700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest rating: 8.1\n",
      "Highest rating: 9.3\n",
      "Average rating: 8.35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "imdb = pd.read_csv('../Grundlagen/DE1_GradedLab01/imdb.csv')\n",
    "\n",
    "print(f\"Lowest rating: {imdb['rating'][imdb['kind'] == 'movie'].min()}\")\n",
    "print(f\"Highest rating: {imdb['rating'][imdb['kind'] == 'movie'].max()}\")\n",
    "print(f\"Average rating: {imdb['rating'][imdb['kind'] == 'movie'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(b) What is the min, max, and the average value of the attribute 'cumulative worldwide gross' for all movies? [0.5 points].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.522652Z",
     "start_time": "2024-03-29T14:33:41.517873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleansing\n",
    "imdb['cumulative worldwide gross'] = imdb['cumulative worldwide gross'].str.replace(r'[\\$,]', '', regex=True)\n",
    "imdb['cumulative worldwide gross'] = imdb['cumulative worldwide gross'].str.split().str[0]\n",
    "imdb['cumulative worldwide gross'] = imdb['cumulative worldwide gross'].str.replace('000000000', '0', regex=True)\n",
    "imdb['cumulative worldwide gross'] = pd.to_numeric(imdb['cumulative worldwide gross'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest cumulative worldwide gross: 6540000\n",
      "Highest cumulative worldwide gross: 2797800564\n",
      "Average cumulative worldwide gross: 390489624.68\n"
     ]
    }
   ],
   "source": [
    "# Queries\n",
    "print(f\"Lowest cumulative worldwide gross: {imdb['cumulative worldwide gross'][imdb['kind'] == 'movie'].min()}\")\n",
    "print(f\"Highest cumulative worldwide gross: {imdb['cumulative worldwide gross'][imdb['kind'] == 'movie'].max()}\")\n",
    "print(f\"Average cumulative worldwide gross: {imdb['cumulative worldwide gross'][imdb['kind'] == 'movie'].mean():.2f}\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.532063Z",
     "start_time": "2024-03-29T14:33:41.522652Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(c) What is the min, max, and the average value of the attribute 'cumulative worldwide gross' grouped by genre of the movies? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.540420Z",
     "start_time": "2024-03-29T14:33:41.533068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert values of this column to lists\n",
    "imdb['genres'] = imdb['genres'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "# Get all unique genres\n",
    "genres = []\n",
    "for cell in imdb['genres']:\n",
    "    for element in cell:\n",
    "        genres.append(element)\n",
    "\n",
    "genres = list(set(genres))\n",
    "genres.sort()\n",
    "print(genres)\n",
    "\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.548831Z",
     "start_time": "2024-03-29T14:33:41.541426Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) What is the profit (defined as cumulative worldwide gross - budget) of each movie? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.558680Z",
     "start_time": "2024-03-29T14:33:41.549836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleansing\n",
    "imdb['budget'] = imdb['budget'].str.replace(r'[\\$,]', '', regex=True)\n",
    "imdb['budget'] = imdb['budget'].str.split().str[0]\n",
    "imdb['budget'] = imdb['budget'].str.replace('000000000', '0', regex=True)\n",
    "imdb['budget'] = pd.to_numeric(imdb['budget'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                title  net profit\n0                            The Shawshank Redemption    33500000\n1                                       The Godfather   239066411\n2                                     The Dark Knight   819558444\n3                                    Schindler's List   199000000\n4                                        Pulp Fiction   205928762\n..                                                ...         ...\n92  Pirates of the Caribbean: The Curse of the Bla...   514264015\n93                                            Aladdin   476050219\n94                               Beauty and the Beast   399967620\n95                                           The Help   191639112\n96                                 Dances with Wolves   402200000\n\n[97 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>net profit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The Shawshank Redemption</td>\n      <td>33500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The Godfather</td>\n      <td>239066411</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The Dark Knight</td>\n      <td>819558444</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Schindler's List</td>\n      <td>199000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pulp Fiction</td>\n      <td>205928762</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n      <td>514264015</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>Aladdin</td>\n      <td>476050219</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Beauty and the Beast</td>\n      <td>399967620</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>The Help</td>\n      <td>191639112</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Dances with Wolves</td>\n      <td>402200000</td>\n    </tr>\n  </tbody>\n</table>\n<p>97 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Queries\n",
    "imdb['net profit'] = imdb['cumulative worldwide gross'] - imdb['budget']\n",
    "imdb[['title', 'net profit']][imdb['kind'] == 'movie']"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:41.574760Z",
     "start_time": "2024-03-29T14:33:41.559692Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(e)  What is the min, max, and the average value of the atttribute 'opening weekend united states' per month? [1 point].__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:27:04.608009Z",
     "start_time": "2024-03-29T15:27:04.602360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleansing\n",
    "imdb['opening weekend united states'] = imdb['opening weekend united states'].str.replace(r'[\\$,]', '', regex=True)\n",
    "imdb['opening weekend date united states'] = imdb['opening weekend united states']\n",
    "imdb['opening weekend united states gross'] = imdb['opening weekend united states'].str.split().str[0].astype(int)\n",
    "imdb['opening weekend date united states'] = imdb['opening weekend date united states'].str.split().str[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create dataframe with month and revenue for opening weekends\n",
    "imdb_month_revenue = pd.DataFrame()\n",
    "imdb_month_revenue['month'] = imdb['opening weekend date united states'][imdb['kind'] == 'movie'].apply(lambda x: x[1])\n",
    "imdb_month_revenue['revenue'] = imdb['opening weekend united states gross'][imdb['kind'] == 'movie'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Queries\n",
    "min_revenue = imdb_month_revenue.groupby(['month']).min().astype(int).sort_values('revenue', ascending=False)\n",
    "max_revenue = imdb_month_revenue.groupby(['month']).max().astype(int).sort_values('revenue', ascending=False)\n",
    "average_revenue = imdb_month_revenue.groupby(['month']).mean().astype(int).sort_values('revenue', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:35:19.133137Z",
     "start_time": "2024-03-29T15:35:19.125568Z"
    }
   },
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       revenue_min  revenue_max  revenue_avg\nmonth                                       \nMay       34819017     68108790     51463903\nFeb       13766814     41062440     30245305\nAug         645363     26681262     17097305\nJun         340456    110307189     39295741\nMar         235488     88411916     23604512\nSep         212440     20817053      7305612\nDec         179953     35363376     12879034\nJul         137301    160887295     41997361\nNov          99761     70467623     18304484\nOct          64770     96202337     19300409\nJan          15172     17754905      7363771\nApr          12562    357115007    110242997",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>revenue_min</th>\n      <th>revenue_max</th>\n      <th>revenue_avg</th>\n    </tr>\n    <tr>\n      <th>month</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>May</th>\n      <td>34819017</td>\n      <td>68108790</td>\n      <td>51463903</td>\n    </tr>\n    <tr>\n      <th>Feb</th>\n      <td>13766814</td>\n      <td>41062440</td>\n      <td>30245305</td>\n    </tr>\n    <tr>\n      <th>Aug</th>\n      <td>645363</td>\n      <td>26681262</td>\n      <td>17097305</td>\n    </tr>\n    <tr>\n      <th>Jun</th>\n      <td>340456</td>\n      <td>110307189</td>\n      <td>39295741</td>\n    </tr>\n    <tr>\n      <th>Mar</th>\n      <td>235488</td>\n      <td>88411916</td>\n      <td>23604512</td>\n    </tr>\n    <tr>\n      <th>Sep</th>\n      <td>212440</td>\n      <td>20817053</td>\n      <td>7305612</td>\n    </tr>\n    <tr>\n      <th>Dec</th>\n      <td>179953</td>\n      <td>35363376</td>\n      <td>12879034</td>\n    </tr>\n    <tr>\n      <th>Jul</th>\n      <td>137301</td>\n      <td>160887295</td>\n      <td>41997361</td>\n    </tr>\n    <tr>\n      <th>Nov</th>\n      <td>99761</td>\n      <td>70467623</td>\n      <td>18304484</td>\n    </tr>\n    <tr>\n      <th>Oct</th>\n      <td>64770</td>\n      <td>96202337</td>\n      <td>19300409</td>\n    </tr>\n    <tr>\n      <th>Jan</th>\n      <td>15172</td>\n      <td>17754905</td>\n      <td>7363771</td>\n    </tr>\n    <tr>\n      <th>Apr</th>\n      <td>12562</td>\n      <td>357115007</td>\n      <td>110242997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge and name the columns after the previous DataFrame\n",
    "revenue_month = pd.merge(min_revenue, max_revenue, on='month', how='outer', suffixes=('_min', '_max'))\n",
    "revenue_month = pd.merge(revenue_month, average_revenue, on='month', how='outer')\n",
    "revenue_month = revenue_month.rename(columns={'revenue': 'revenue_avg'})\n",
    "revenue_month\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T15:35:20.680954Z",
     "start_time": "2024-03-29T15:35:20.669748Z"
    }
   },
   "execution_count": 142
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 02: Unstructured Data [6 points]. \n",
    "This time use the files imdb.csv from Task 01 and the imdb2.csv file. In this task we mainly use the content of the attribute 'plot' for the implementation of a retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(a)  Read the files imdb.csv and imdb2.csv in a dataframe called imdb. Add a column which is called 'plotterms' to each item. The new column should contain all terms (lower-case and cleaned from special characters) from the plot attribute which are not contained in the stopwords_english.txt file. [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T14:33:42.375089Z",
     "start_time": "2024-03-29T14:33:41.606397Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imdb2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimdb2.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m data\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    602\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    604\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 605\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1439\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1733\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1734\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1735\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[0;32m   1736\u001B[0m     f,\n\u001B[0;32m   1737\u001B[0m     mode,\n\u001B[0;32m   1738\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1739\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1740\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m   1741\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[0;32m   1742\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1743\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m   1744\u001B[0m )\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    857\u001B[0m             handle,\n\u001B[0;32m    858\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    859\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    860\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    861\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    862\u001B[0m         )\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'imdb2.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('imdb2.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(b)  Create an inverted index for the terms in the 'plotterms' column. Use a datastructure of your choice for the implementation [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-29T14:33:42.376603Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(c) Take the inverted index and create the posting list for the query 'american'. Return the posting list as well as the top5 items scored by the rating attribute. [0.5 points]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-29T14:33:42.376603Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(d) Take the inverted index and create the posting lists for the query terms 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot). Your merging algorithm should be efficient and reduce the number of comparison to a minimum. Don't use existing python methods (like intersect or in) for the merge algorithm. Return the merged posting list as well as the top5 items scored by the rating attribute. [1 point]__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-29T14:33:42.377604Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(e) Extend your index to be able to rank the resulting items from Task 2d by the occurrence of search terms in the plotterms. Execute the query 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot) again and print the resulting items.  [1 point]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-29T14:33:42.378604Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### __(f) Use the TF-IDF score and the cosine similarity to execute the query 'american' and 'dream' (the term 'american' as well as the term 'dream' should be contained in the plot) against all plots in the collection. Print the results with the corresponding ranking score. Also execute the query 'american' or 'dream' (the term 'american' or the term 'dream' should be contained in the plot).  [1.5 points]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-29T14:33:42.379604Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
