{
 "cells": [
  {
   "cell_type": "code",
   "id": "e0ba8872a01f5b4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T09:18:56.415977Z",
     "start_time": "2025-02-24T09:18:56.095592Z"
    }
   },
   "source": [
    "# Binary to Integer and Integer to Binary\n",
    "from bitstring import BitArray\n",
    "from charset_normalizer.constant import UTF8_MAXIMAL_ALLOCATION\n",
    "from nbconvert import export\n",
    "\n",
    "# Binary to Integer\n",
    "binary_string = \"010010\"\n",
    "b = BitArray(bin=binary_string)\n",
    "print(b.int)  # Output: 13\n",
    "\n",
    "# Integer to Binary\n",
    "integer_value = 44\n",
    "b = BitArray(int=integer_value, length=8)\n",
    "print(b.bin)  # Output: 00001101"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "00101100\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T11:08:21.735343Z",
     "start_time": "2025-01-17T11:08:21.730752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ASCII to Binary and Binary to ASCII\n",
    "from bitstring import BitArray\n",
    "\n",
    "# ASCII to Binary\n",
    "ascii_text = \"nice\"\n",
    "binary_bits = ''.join(BitArray(bytes=char.encode()).bin for char in ascii_text)\n",
    "print(binary_bits)\n",
    "\n",
    "# Binary to ASCII\n",
    "binary_string = \"0110010001110101001000000110101101101100011001010110100101101110011001010111001000100000011100000110100101101101011011010110010101101100\"\n",
    "ascii_text = ''.join(BitArray(bin=binary_string[i:i+8]).bytes.decode() for i in range(0, len(binary_string), 8))\n",
    "print(ascii_text)"
   ],
   "id": "73de9f78bbc74e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01101110011010010110001101100101\n",
      "du kleiner pimmel\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T07:31:02.793138Z",
     "start_time": "2025-01-21T07:31:02.732830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Levenshtein Distance\n",
    "import Levenshtein\n",
    "\n",
    "word_1 = \"mr. geil\"\n",
    "word_2 = \"sieg heil\"\n",
    "distance = Levenshtein.distance(word_1, word_2)\n",
    "print(distance)"
   ],
   "id": "50d502f94c2a8afa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T07:32:44.097868Z",
     "start_time": "2025-01-21T07:32:44.092184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ordinal / One-Hot Encoding\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "data = {\"Marke\": [\"saab\", \"bmw\", \"mitsubishi\", \"mitsubishi\", \"bmw\"],\n",
    "        \"Form\": [\"limousine\", \"cabrio\", \"kombi\", \"kombi\", \"limousine\"],\n",
    "        \"Preis\": [20000, 30000, 25000, 25000, 30000]}\n",
    "df_ordinal = pd.DataFrame(data)\n",
    "df_onehot = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# OrdinalEncoder for categorical columns\n",
    "encoder = OrdinalEncoder()\n",
    "df_ordinal[[\"Marke_ordinal\", \"Form_ordinal\"]] = encoder.fit_transform(df_ordinal[[\"Marke\", \"Form\"]])\n",
    "\n",
    "\n",
    "# One-Hot Encoding for categorical columns\n",
    "df_onehot = pd.get_dummies(df_onehot, columns=[\"Marke\", \"Form\"])"
   ],
   "id": "a2ac215e1aea5ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Preis  Marke_bmw  Marke_mitsubishi  Marke_saab  Form_cabrio  Form_kombi  \\\n",
      "0  20000      False             False        True        False       False   \n",
      "1  30000       True             False       False         True       False   \n",
      "2  25000      False              True       False        False        True   \n",
      "3  25000      False              True       False        False        True   \n",
      "4  30000       True             False       False        False       False   \n",
      "\n",
      "   Form_limousine  \n",
      "0            True  \n",
      "1           False  \n",
      "2           False  \n",
      "3           False  \n",
      "4            True  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Similarity\n",
    "\n",
    "set_1 = (1, 0, 1, 0)\n",
    "set_2 = (0, 0, 1, 1)\n",
    "\n",
    "# Jaccard Similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "jaccard_similarity = jaccard_score(set_1, set_2)\n",
    "print(f\"Jaccard Similarity: {jaccard_similarity}\")\n",
    "\n",
    "# Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "cosine_similarity = cosine_similarity(np.array(set_1).reshape(1, -1), np.array(set_2).reshape(1, -1))\n",
    "print(f\"Cosine Similarity: {cosine_similarity}\")\n",
    "\n",
    "# Manhattan Distance\n",
    "from scipy.spatial.distance import cityblock\n",
    "manhattan_distance = cityblock(set_1, set_2)\n",
    "print(f\"Manhattan Distance: {manhattan_distance}\")"
   ],
   "id": "67df8d8abb57e826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T09:43:13.558670Z",
     "start_time": "2025-01-20T09:43:13.550098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cosine Similarity Matrix\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with the first column as the index (row labels like 'A', 'B', etc.)\n",
    "ratings = pd.read_csv(\"similarity.csv\", delimiter=\",\", index_col=0)\n",
    "\n",
    "# Ensure only numeric data is used for the calculation\n",
    "numeric_data = ratings.select_dtypes(include=[float, int])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim_matrix = cosine_similarity(numeric_data)\n",
    "\n",
    "# Create a DataFrame with similarity values\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=ratings.index, columns=ratings.index)\n",
    "\n",
    "# Print the Cosine Similarity Matrix\n",
    "print(cosine_sim_df)"
   ],
   "id": "899517a4360b70de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A         B         C         D         E         F         X\n",
      "A  1.000000  0.650791  0.976187  0.997054  0.998868  0.795432  0.998868\n",
      "B  0.650791  1.000000  0.800000  0.707107  0.613941  0.977802  0.613941\n",
      "C  0.976187  0.800000  1.000000  0.989949  0.964764  0.907959  0.964764\n",
      "D  0.997054  0.707107  0.989949  1.000000  0.992278  0.839570  0.992278\n",
      "E  0.998868  0.613941  0.964764  0.992278  1.000000  0.765705  1.000000\n",
      "F  0.795432  0.977802  0.907959  0.839570  0.765705  1.000000  0.765705\n",
      "X  0.998868  0.613941  0.964764  0.992278  1.000000  0.765705  1.000000\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T08:51:18.992006Z",
     "start_time": "2025-01-20T08:51:18.984014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manhattan Distance Matrix\n",
    "\n",
    "from scipy.spatial.distance import cityblock\n",
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"similarity.csv\", delimiter=\",\", index_col=0)\n",
    "numeric_data = ratings.select_dtypes(include=[float, int])\n",
    "\n",
    "manhattan_distance_matrix = pd.DataFrame(index=ratings.index, columns=ratings.index)\n",
    "for i in ratings.index:\n",
    "    for j in ratings.index:\n",
    "        manhattan_distance_matrix.loc[i, j] = cityblock(numeric_data.loc[i], numeric_data.loc[j])\n",
    "\n",
    "print(manhattan_distance_matrix)"
   ],
   "id": "2397ec6b15d07c37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   E   F\n",
      "A   0  11   4   3   5  10\n",
      "B  11   0   7   8  10   9\n",
      "C   4   7   0   1   7  12\n",
      "D   3   8   1   0   6  11\n",
      "E   5  10   7   6   0  11\n",
      "F  10   9  12  11  11   0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setting up control group\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "# Split the data into training and control sets\n",
    "train_df, control_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add a \"training\" column to indicate the split\n",
    "train_df['training'] = 1  # 1 for training\n",
    "control_df['training'] = 0  # 0 for control\n",
    "\n",
    "# Combine the two DataFrames back together\n",
    "df_split = pd.concat([train_df, control_df]).sort_index()\n",
    "df_split"
   ],
   "id": "46a6767528253c3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T08:52:17.788690Z",
     "start_time": "2025-01-21T08:52:17.777921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data.csv\", delimiter=\",\")\n",
    "df[df[\"Diagnose\"] == \"M\"] = df[df[\"Diagnose\"] == \"M\"].replace(\"M\", 1)\n",
    "df[df[\"Diagnose\"] == \"B\"] = df[df[\"Diagnose\"] == \"B\"].replace(\"B\", 0)\n",
    "\n",
    "df[df[\"Risiko\"] == \"Gering\"] = df[df[\"Risiko\"] == \"Gering\"].replace(\"Gering\", 1)\n",
    "df[df[\"Risiko\"] == \"Mittel\"] = df[df[\"Risiko\"] == \"Mittel\"].replace(\"Mittel\", 2)\n",
    "df[df[\"Risiko\"] == \"Hoch\"] = df[df[\"Risiko\"] == \"Hoch\"].replace(\"Hoch\", 3)\n",
    "\n",
    "\n",
    "# export to csv\n",
    "df.to_csv(\"data.csv\", index=False)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
