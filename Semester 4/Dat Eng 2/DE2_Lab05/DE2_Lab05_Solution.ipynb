{"cells":[{"cell_type":"markdown","source":["# Data Engineering 2: Lab 05 - Solution\n---------------"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"487b2965-ec93-4e39-b0bc-06caf462c7eb","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##### Task 01: Transformation with map and flatMap\n###### Convert all words in a rdd to lowercase and split the lines of the document 'blogposts' using space."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b394e68e-8e18-4d2e-9ed2-3c450a40034b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# TODO: read the file blogtexts into an RDD rdd\nrdd = sc.textFile(\"/FileStore/tables/blogtexts\")\n\n# TODO: print the first 5 entries of the rdd\nrdd.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f6e6d11d-06b4-47a6-9726-f264ced53c1f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# TODO: define a function which returns all tokens in lowercase\ndef Func(lines):\n      lines = lines.lower()\n      lines = lines.split()\n      return lines\n    \n# TODO: apply the function to the RDD by using map and create a new RDD rdd1\nrdd1 = rdd.map(Func)\n\n# TODO: print the first 5 entries of the rdd1\nrdd1.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1805581b-aa8e-4e0c-9e8e-4911ff5e457c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[3]: [['think',\n  'of',\n  'it',\n  'for',\n  'a',\n  'moment',\n  '–',\n  '1',\n  'qunitillion',\n  '=',\n  '1',\n  'million',\n  'billion!',\n  'can',\n  'you',\n  'imagine',\n  'how',\n  'many',\n  'drives',\n  '/',\n  'cds',\n  '/',\n  'blue-ray',\n  'dvds',\n  'would',\n  'be',\n  'required',\n  'to',\n  'store',\n  'them?',\n  'it',\n  'is',\n  'difficult',\n  'to',\n  'imagine',\n  'this',\n  'scale',\n  'of',\n  'data',\n  'generation',\n  'even',\n  'as',\n  'a',\n  'data',\n  'science',\n  'professional.',\n  'while',\n  'this',\n  'pace',\n  'of',\n  'data',\n  'generation',\n  'is',\n  'very',\n  'exciting,',\n  'it',\n  'has',\n  'created',\n  'entirely',\n  'new',\n  'set',\n  'of',\n  'challenges',\n  'and',\n  'has',\n  'forced',\n  'us',\n  'to',\n  'find',\n  'new',\n  'ways',\n  'to',\n  'handle',\n  'big',\n  'huge',\n  'data',\n  'effectively.'],\n [],\n ['big',\n  'data',\n  'is',\n  'not',\n  'a',\n  'new',\n  'phenomena.',\n  'it',\n  'has',\n  'been',\n  'around',\n  'for',\n  'a',\n  'while',\n  'now.',\n  'however,',\n  'it',\n  'has',\n  'become',\n  'really',\n  'important',\n  'with',\n  'this',\n  'pace',\n  'of',\n  'data',\n  'generation.',\n  'in',\n  'past,',\n  'several',\n  'systems',\n  'were',\n  'developed',\n  'for',\n  'processing',\n  'big',\n  'data.',\n  'most',\n  'of',\n  'them',\n  'were',\n  'based',\n  'on',\n  'mapreduce',\n  'framework.',\n  'these',\n  'frameworks',\n  'typically',\n  'rely',\n  'on',\n  'use',\n  'of',\n  'hard',\n  'disk',\n  'for',\n  'saving',\n  'and',\n  'retrieving',\n  'the',\n  'results.',\n  'however,',\n  'this',\n  'turns',\n  'out',\n  'to',\n  'be',\n  'very',\n  'costly',\n  'in',\n  'terms',\n  'of',\n  'time',\n  'and',\n  'speed.'],\n [],\n ['on',\n  'the',\n  'other',\n  'hand,',\n  'organizations',\n  'have',\n  'never',\n  'been',\n  'more',\n  'hungrier',\n  'to',\n  'add',\n  'a',\n  'competitive',\n  'differentiation',\n  'through',\n  'understanding',\n  'this',\n  'data',\n  'and',\n  'offering',\n  'its',\n  'customer',\n  'a',\n  'much',\n  'better',\n  'experience.',\n  'imagine',\n  'how',\n  'valuable',\n  'would',\n  'be',\n  'facebook,',\n  'if',\n  'it',\n  'did',\n  'not',\n  'understand',\n  'your',\n  'interests',\n  'well?',\n  'the',\n  'traditional',\n  'hard',\n  'disk',\n  'based',\n  'mapreduce',\n  'kind',\n  'of',\n  'frameworks',\n  'do',\n  'not',\n  'help',\n  'much',\n  'to',\n  'address',\n  'this',\n  'challenge.']]"]}],"execution_count":0},{"cell_type":"code","source":["# TODO: apply the function to the RDD by using flatMap and create a new RDD rdd2\nrdd2 = rdd.flatMap(Func)\n\n# TODO: print the first 5 entries of the rdd2\nrdd2.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"255e099b-d024-4669-954f-862268d2e883","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[5]: ['think', 'of', 'it', 'for', 'a']"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Task 02: Transformation with filter\n###### Remove all stopwords from the token list."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e87d5aeb-4d25-4965-ab9b-3afa8d08b941","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# stopword list\nstopwords = ['is', 'am', 'are', 'the', 'for', 'a']\n\n# TODO: create a RDD rdd3 by using the filter method with just tokens which are not contained in the stopwords list\nrdd3 = rdd2.filter(lambda x: x not in stopwords)\n\n# TODO: print the first 5 entries of the rdd3\nrdd3.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f6b23bb9-4fce-4d1d-a183-e4f4bd55ce5e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[6]: ['think', 'of', 'it', 'moment', '–']"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Task 03: Transformation with groupBy\n###### After getting the results into rdd3, we want to group the words in rdd3 based on which letters they start with. For example, suppose I want to group each word of rdd3 based on first 2 characters."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02cb863b-9c68-47b3-9871-86e1167f00c7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# TODO: create a RDD rdd4 by using the groupBy method grouped based on the first 2 characters\nrdd4 = rdd3.groupBy(lambda w: w[0:2])\n# TODO: print the first 5 entries of the rdd4 with the corresponding grouped values\nprint([(k, list(v)) for (k, v) in rdd4.take(5)])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae7a6aa6-2e60-4dda-80f5-cc05c2375e10","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[('of', ['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'offering', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'offering', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']), ('1', ['1', '1']), ('qu', ['qunitillion', 'querying', 'querying', 'querying', 'question', 'query', 'questions']), ('=', ['=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=']), ('mi', ['million', 'minimal', 'millions', 'minutes.', 'mind', 'might', 'missing'])]\n"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Task 04: Transformation with groupByKey / reduceByKey \n###### What if we want to calculate how many times each word is coming in corpus ?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0762bf65-128b-4f03-af0f-0769aae84a54","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# TODO: create a RDD rdd3_mapped from rdd3 with has the token as key and 1 as value\nrdd3_mapped = rdd3.map(lambda x: (x, 1))\n# TODO: create a RDD rdd3_grouped with is grouped by the key\nrdd3_grouped = rdd3_mapped.groupByKey()\n# TODO: print the first 5 entries of rdd3_grouped\nrdd3_grouped.take(5)\n# TODO: print the first 5 entries of the rdd3_grouped with the corresponding grouped values\nprint(list((j[0], list(j[1])) for j in rdd3_grouped.take(5)))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a5b370f9-744b-46ff-a843-5753e1aa0ed6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[('think', [1, 1]), ('of', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), ('1', [1, 1]), ('qunitillion', [1]), ('=', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n"]}],"execution_count":0},{"cell_type":"code","source":["# TODO: create a RDD rdd3_freq_of_words with count as key and the words as value and sorted by the key\nrdd3_freq_of_words = rdd3_grouped.mapValues(sum).map(lambda x: (x[1],x[0])).sortByKey(False)\n# TODO: print the top 10 of rdd3_freq_of_words\nrdd3_freq_of_words.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"18738567-0b55-485c-95d8-cc10e907623a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[18]: [(164, 'to'),\n (143, 'in'),\n (122, 'of'),\n (106, 'and'),\n (103, 'we'),\n (69, 'spark'),\n (64, 'this'),\n (63, 'data'),\n (55, 'can'),\n (52, 'apache')]"]}],"execution_count":0},{"cell_type":"code","source":["# TODO: also try reduceByKey to produce the same result\nrdd3_mapped.reduceByKey(lambda x,y: x+y).map(lambda x:(x[1],x[0])).sortByKey(False).take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fec25b30-b5a2-4b3a-b598-1734783f0c71","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[19]: [(164, 'to'),\n (143, 'in'),\n (122, 'of'),\n (106, 'and'),\n (103, 'we'),\n (69, 'spark'),\n (64, 'this'),\n (63, 'data'),\n (55, 'can'),\n (52, 'apache')]"]}],"execution_count":0},{"cell_type":"markdown","source":["##### Task 05: Parallelize a RDD to n partitions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"86bf85fb-14f1-4791-bc11-313789be1053","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import numpy as np\n\n# TODO: create an RDD rdd_dis5 with 5 as the number of partitions\n# TODO: np.arange(0, 30, 2) - give the list from 0 to 30 with step 2.\nrdd_dis5 = sc.parallelize(np.arange(0, 30, 2), 5)\n# TODO: print the RDD rdd_dis\nprint(rdd_dis5.collect())\n# TODO: print the partitions of the RDD rdd_dis\nprint(rdd_dis5.glom().collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8fa6b32c-2983-4863-bf35-ad49a7edb259","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n[[0, 2, 4], [6, 8, 10], [12, 14, 16], [18, 20, 22], [24, 26, 28]]\n"]}],"execution_count":0},{"cell_type":"code","source":["# TODO: create an RDD rdd_dis2  with 2 as number of partitions\n# TODO: np.arange(0, 30, 2) - give the list from 0 to 30 with step 2.\nrdd_dis2 = sc.parallelize(np.arange(0, 30, 2), 2)\n# TODO: print the RDD rdd_dis\nprint(rdd_dis2.collect())\n# TODO: print the partitions of the RDD rdd_dis\nprint(rdd_dis2.glom().collect())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e611156-769a-4446-af62-3ca8e4fe5939","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]\n[[0, 2, 4, 6, 8, 10, 12], [14, 16, 18, 20, 22, 24, 26, 28]]\n"]}],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.6","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"DE2_Lab05_Solution","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2175610004198510}},"nbformat":4,"nbformat_minor":0}
